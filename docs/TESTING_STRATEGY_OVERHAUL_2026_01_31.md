# Testing Strategy Overhaul - Concierge Collector

**Date:** January 31, 2026  
**Status:** PLANNING  
**Scope:** Frontend (JavaScript/Vitest) + Backend (Python/pytest)

---

## ðŸŽ¯ Executive Summary

AnÃ¡lise completa revelou **boas fundaÃ§Ãµes mas gaps crÃ­ticos**:

### SituaÃ§Ã£o Atual
- âœ… **Frontend:** 339 testes (332 passing, 7 failing) - boa cobertura de core
- âš ï¸ **Backend:** 60+ testes, pytest nÃ£o instalado no ambiente de desenvolvimento
- âŒ **ServiÃ§os refatorados:** 0 testes (10 novos serviÃ§os sem cobertura)
- âŒ **Integration E2E:** cobertura superficial
- âŒ **Performance/Load:** nÃ£o testado

### Problemas Identificados

#### 1. **ServiÃ§os Refatorados Sem Testes** ðŸ”´ CRÃTICO
Acabamos de refatorar 3 God Objects em 10 serviÃ§os (~3,500 linhas) sem adicionar testes:
- AudioRecordingService.js (370 linhas) - **0 testes**
- AudioConversionService.js (412 linhas) - **0 testes**
- RecordingUIManager.js (379 linhas) - **0 testes**
- RecordingStateManager.js (321 linhas) - **0 testes**
- ConceptValidationService.js (281 linhas) - **0 testes**
- ImageProcessingService.js (279 linhas) - **0 testes**
- ConceptUIManager.js (397 linhas) - **0 testes**
- ConceptExtractionService.js (348 linhas) - **0 testes**
- PlacesSearchService.js (330 linhas) - **0 testes**
- PlacesUIManager.js (336 linhas) - **0 testes**

#### 2. **Testes Desatualizados** âš ï¸ MÃ‰DIO
Testes de mÃ³dulos refatorados ainda testam cÃ³digo antigo:
- `test_recordingModule.test.js` - testa mÃ³dulo de 2,421 linhas (agora 516)
- `test_conceptModule.test.js` - testa mÃ³dulo de 2,511 linhas (agora 609)
- `test_placesModule.test.js` - **nÃ£o existe!**

#### 3. **Testes Falhando** âš ï¸ MÃ‰DIO
- 7 testes failing relacionados a inicializaÃ§Ã£o do DataStore
- test_syncManagerV3.test.js: 3 falhas (PATCH partial updates)
- test_realProduction.test.js: 2 falhas (DataStore null)
- test_integration_real.test.js: 5 falhas (DataStore.db.close)

#### 4. **Backend Environment** âš ï¸ BAIXO
- pytest nÃ£o instalado no ambiente local de desenvolvimento
- Testes backend nÃ£o sÃ£o executados regularmente

#### 5. **Sem Testes E2E Reais** ðŸ”´ CRÃTICO
- Fluxo completo audio â†’ transcription â†’ concepts â†’ MongoDB nÃ£o testado
- Conflict resolution UI nÃ£o testada
- OAuth flow nÃ£o testado

---

## ðŸ“Š Gap Analysis

### Frontend Testing Gaps

| Categoria | Coverage Atual | Gap | Prioridade |
|-----------|----------------|-----|------------|
| **Novos ServiÃ§os** | 0% (0/10) | 100% | ðŸ”´ CRÃTICA |
| **Services/utilities** | 25% (1/4 utils) | 75% | ðŸ”´ ALTA |
| **MÃ³dulos refatorados** | 60% (desatualizado) | 40% | ðŸŸ¡ MÃ‰DIA |
| **Integration E2E** | 20% | 80% | ðŸ”´ ALTA |
| **UI Components** | 10% | 90% | ðŸŸ¡ MÃ‰DIA |
| **Error Boundaries** | 40% | 60% | ðŸŸ¢ BAIXA |

### Backend Testing Gaps

| Categoria | Coverage Atual | Gap | Prioridade |
|-----------|----------------|-----|------------|
| **AI Orchestrate** | 0% (bugs) | 100% | ðŸ”´ CRÃTICA |
| **Audio Transcription** | 0% (bugs) | 100% | ðŸ”´ ALTA |
| **Conflict Resolution** | 30% | 70% | ðŸŸ¡ MÃ‰DIA |
| **Performance** | 10% | 90% | ðŸŸ¡ MÃ‰DIA |
| **Error Handling** | 50% | 50% | ðŸŸ¢ BAIXA |

---

## ðŸ—ï¸ Nova Estrutura de Testes (Proposta)

### Frontend - ReorganizaÃ§Ã£o Completa

```
tests/
â”œâ”€â”€ README.md                        # DocumentaÃ§Ã£o atualizada
â”œâ”€â”€ setup/
â”‚   â”œâ”€â”€ conftest.js                  # Setup global
â”‚   â”œâ”€â”€ mocks/                       # Mocks centralizados
â”‚   â”‚   â”œâ”€â”€ browser.mock.js          # MediaRecorder, getUserMedia
â”‚   â”‚   â”œâ”€â”€ indexeddb.mock.js        # Dexie mocks
â”‚   â”‚   â”œâ”€â”€ api.mock.js              # API responses
â”‚   â”‚   â””â”€â”€ dom.mock.js              # DOM elements
â”‚   â””â”€â”€ fixtures/                    # Test data
â”‚       â”œâ”€â”€ entities.fixture.js
â”‚       â”œâ”€â”€ curations.fixture.js
â”‚       â””â”€â”€ audio.fixture.js
â”‚
â”œâ”€â”€ unit/                            # NOVO: Testes unitÃ¡rios isolados
â”‚   â”œâ”€â”€ services/                    # â­ PRIORIDADE MÃXIMA
â”‚   â”‚   â”œâ”€â”€ AudioRecordingService.test.js       # MISSING
â”‚   â”‚   â”œâ”€â”€ AudioConversionService.test.js      # MISSING
â”‚   â”‚   â”œâ”€â”€ RecordingUIManager.test.js          # MISSING
â”‚   â”‚   â”œâ”€â”€ RecordingStateManager.test.js       # MISSING
â”‚   â”‚   â”œâ”€â”€ ConceptValidationService.test.js    # MISSING
â”‚   â”‚   â”œâ”€â”€ ImageProcessingService.test.js      # MISSING
â”‚   â”‚   â”œâ”€â”€ ConceptUIManager.test.js            # MISSING
â”‚   â”‚   â”œâ”€â”€ ConceptExtractionService.test.js    # MISSING
â”‚   â”‚   â”œâ”€â”€ PlacesSearchService.test.js         # MISSING
â”‚   â”‚   â””â”€â”€ PlacesUIManager.test.js             # MISSING
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                       # Utilities
â”‚   â”‚   â”œâ”€â”€ uiHelpers.test.js                   # MISSING
â”‚   â”‚   â”œâ”€â”€ errorHandling.test.js               # MISSING
â”‚   â”‚   â”œâ”€â”€ apiUtils.test.js                    # MISSING
â”‚   â”‚   â””â”€â”€ audioUtils.test.js                  # MISSING
â”‚   â”‚
â”‚   â””â”€â”€ core/                        # Core infrastructure (jÃ¡ existe)
â”‚       â”œâ”€â”€ config.test.js           # âœ… EXISTS (19 tests)
â”‚       â”œâ”€â”€ logger.test.js           # âœ… EXISTS (22 tests)
â”‚       â”œâ”€â”€ errorManager.test.js     # âœ… EXISTS (25 tests)
â”‚       â””â”€â”€ moduleWrapper.test.js    # âœ… EXISTS (27 tests)
â”‚
â”œâ”€â”€ integration/                     # NOVO: Testes de integraÃ§Ã£o entre mÃ³dulos
â”‚   â”œâ”€â”€ modules/                     # MÃ³dulos refatorados (atualizar)
â”‚   â”‚   â”œâ”€â”€ recordingModule.test.js            # âš ï¸ UPDATE NEEDED
â”‚   â”‚   â”œâ”€â”€ conceptModule.test.js              # âš ï¸ UPDATE NEEDED
â”‚   â”‚   â”œâ”€â”€ placesModule.test.js               # âŒ MISSING
â”‚   â”‚   â”œâ”€â”€ entityModule.test.js               # âŒ MISSING
â”‚   â”‚   â””â”€â”€ syncModule.test.js                 # âš ï¸ UPDATE (syncManagerV3)
â”‚   â”‚
â”‚   â”œâ”€â”€ workflows/                   # Fluxos completos
â”‚   â”‚   â”œâ”€â”€ audioToMongoDB.test.js             # MISSING - audio â†’ DB
â”‚   â”‚   â”œâ”€â”€ conceptExtraction.test.js          # MISSING - full pipeline
â”‚   â”‚   â”œâ”€â”€ placeImport.test.js                # MISSING - Places â†’ Entity
â”‚   â”‚   â”œâ”€â”€ conflictResolution.test.js         # MISSING - merge conflicts
â”‚   â”‚   â””â”€â”€ offlineSync.test.js                # MISSING - offline â†’ online
â”‚   â”‚
â”‚   â””â”€â”€ api/                         # API integration (jÃ¡ existe parcialmente)
â”‚       â”œâ”€â”€ apiService.test.js       # âœ… EXISTS (60 tests)
â”‚       â”œâ”€â”€ api_integration.test.js  # âœ… EXISTS (12 tests)
â”‚       â””â”€â”€ dataStore.test.js        # âœ… EXISTS (23 tests)
â”‚
â”œâ”€â”€ e2e/                             # NOVO: End-to-End real (Playwright)
â”‚   â”œâ”€â”€ critical/                    # Fluxos crÃ­ticos de negÃ³cio
â”‚   â”‚   â”œâ”€â”€ completeRestaurantFlow.spec.js     # MISSING
â”‚   â”‚   â”œâ”€â”€ audioRecordingFlow.spec.js         # MISSING
â”‚   â”‚   â””â”€â”€ syncFlow.spec.js                   # MISSING
â”‚   â”‚
â”‚   â””â”€â”€ edge-cases/                  # Casos extremos
â”‚       â”œâ”€â”€ networkFailure.spec.js             # MISSING
â”‚       â”œâ”€â”€ browserCompatibility.spec.js       # MISSING
â”‚       â””â”€â”€ dataCorruption.spec.js             # MISSING
â”‚
â”œâ”€â”€ performance/                     # NOVO: Performance benchmarks
â”‚   â”œâ”€â”€ audioProcessing.bench.js               # MISSING
â”‚   â”œâ”€â”€ imageQueue.bench.js                    # MISSING
â”‚   â””â”€â”€ syncPerformance.bench.js               # MISSING
â”‚
â””â”€â”€ legacy/                          # Testes antigos (mover temporariamente)
    â”œâ”€â”€ test_audioTranscription.test.js
    â”œâ”€â”€ test_consoleErrors.test.js
    â”œâ”€â”€ test_integration_real.test.js
    â””â”€â”€ test_realProduction.test.js
```

### Backend - ReorganizaÃ§Ã£o

```
concierge-api-v3/tests/
â”œâ”€â”€ conftest.py                      # Setup global (jÃ¡ existe)
â”œâ”€â”€ fixtures/                        # NOVO: Fixtures organizados
â”‚   â”œâ”€â”€ entities.py
â”‚   â”œâ”€â”€ curations.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â””â”€â”€ places.py
â”‚
â”œâ”€â”€ unit/                            # NOVO: Unit tests isolados
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ test_ai_service.py                 # MISSING
â”‚   â”‚   â”œâ”€â”€ test_transcription_service.py      # MISSING
â”‚   â”‚   â””â”€â”€ test_conflict_resolver.py          # MISSING
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ test_validators.py                 # MISSING
â”‚       â””â”€â”€ test_transformers.py               # MISSING
â”‚
â”œâ”€â”€ integration/                     # Reorganizar existentes
â”‚   â”œâ”€â”€ api/                         # API endpoints
â”‚   â”‚   â”œâ”€â”€ test_auth.py             # âœ… EXISTS (8 tests)
â”‚   â”‚   â”œâ”€â”€ test_entities.py         # âœ… EXISTS (15 tests)
â”‚   â”‚   â”œâ”€â”€ test_curations.py        # âœ… EXISTS (11 tests)
â”‚   â”‚   â”œâ”€â”€ test_concepts.py         # âœ… EXISTS (5 tests)
â”‚   â”‚   â”œâ”€â”€ test_places.py           # âœ… EXISTS (7 tests)
â”‚   â”‚   â””â”€â”€ test_system.py           # âœ… EXISTS (2 tests)
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                          # AI services
â”‚   â”‚   â”œâ”€â”€ test_ai.py               # âš ï¸ UPDATE (fix fixtures)
â”‚   â”‚   â”œâ”€â”€ test_ai_orchestrate.py   # âš ï¸ UPDATE (fix fixtures)
â”‚   â”‚   â””â”€â”€ test_integration_transcription.py  # âš ï¸ UPDATE
â”‚   â”‚
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ test_integration.py      # âœ… EXISTS
â”‚
â”œâ”€â”€ e2e/                             # NOVO: End-to-end backend
â”‚   â””â”€â”€ test_complete_flow.py                  # MISSING
â”‚
â””â”€â”€ performance/                     # NOVO: Performance tests
    â”œâ”€â”€ test_load.py                           # MISSING - load testing
    â””â”€â”€ test_concurrent.py                     # MISSING - concurrent requests
```

---

## ðŸŽ¯ Test Pyramid Strategy

### PirÃ¢mide Ideal (70/20/10)

```
         /\
        /  \  E2E (10%)
       /----\  
      /      \  Integration (20%)
     /--------\
    /          \  Unit (70%)
   /____________\
```

### DistribuiÃ§Ã£o Proposta

| Tipo | Quantidade | % | EsforÃ§o | Prioridade |
|------|------------|---|---------|------------|
| **Unit Tests** | ~150 novos | 70% | 40h | ðŸ”´ MÃXIMA |
| **Integration Tests** | ~40 novos | 20% | 25h | ðŸŸ¡ ALTA |
| **E2E Tests** | ~15 novos | 10% | 20h | ðŸŸ¢ MÃ‰DIA |
| **Performance Tests** | ~10 novos | bonus | 15h | ðŸŸ¢ BAIXA |

---

## ðŸš€ Roadmap de ImplementaÃ§Ã£o

### **Fase 1: Foundation (Week 1) - CRÃTICO** ðŸ”´

**Meta:** Testes unitÃ¡rios para todos os 10 serviÃ§os refatorados

#### Day 1-2: Services Core (Audio)
- âœ… AudioRecordingService.test.js (30 testes)
  - Browser support checks
  - MediaRecorder lifecycle
  - Chunk collection
  - Error handling
  - iOS Safari compatibility

- âœ… AudioConversionService.test.js (35 testes)
  - Strategy pattern (MP3, Opus, WebM, WAV)
  - Format conversion accuracy
  - Fallback chains
  - Error handling
  - Performance benchmarks

- âœ… RecordingStateManager.test.js (25 testes)
  - State machine transitions
  - Queue management
  - Error state recovery
  - Retry logic

#### Day 3: Services Core (Concepts)
- âœ… ConceptValidationService.test.js (30 testes)
  - Duplicate detection
  - Levenshtein distance
  - Category normalization
  - Validation rules

- âœ… ConceptExtractionService.test.js (25 testes)
  - API integration
  - Text parsing
  - Image analysis
  - Merge logic

- âœ… ImageProcessingService.test.js (20 testes)
  - Queue processing
  - Async handling
  - Statistics tracking
  - Error recovery

#### Day 4: Services UI & Places
- âœ… RecordingUIManager.test.js (20 testes)
  - Button states
  - Timer display
  - Visualizer rendering
  - Progress indicators

- âœ… ConceptUIManager.test.js (25 testes)
  - Modal rendering
  - Autocomplete
  - Pills display
  - Similarity warnings

- âœ… PlacesSearchService.test.js (25 testes)
  - API integration
  - Filtering logic
  - Distance calculation
  - Rate limiting

- âœ… PlacesUIManager.test.js (20 testes)
  - Search modal
  - Results rendering
  - Filter controls

#### Day 5: Utilities
- âœ… uiHelpers.test.js (15 testes)
- âœ… errorHandling.test.js (20 testes)
- âœ… apiUtils.test.js (15 testes)
- âœ… audioUtils.test.js (20 testes)

**Deliverable:** 325 unit tests, 100% coverage dos serviÃ§os refatorados

---

### **Fase 2: Integration Updates (Week 2) - ALTA** ðŸŸ¡

**Meta:** Atualizar testes de integraÃ§Ã£o para nova arquitetura

#### Day 1: Fix Failing Tests
- ðŸ”§ Fix test_syncManagerV3.test.js (3 falhas)
- ðŸ”§ Fix test_realProduction.test.js (2 falhas)
- ðŸ”§ Fix test_integration_real.test.js (5 falhas)
- ðŸ”§ Fix DataStore initialization issues

#### Day 2-3: Update Module Tests
- â™»ï¸ Update test_recordingModule.test.js
  - Testar orchestration do mÃ³dulo refatorado
  - Testar integraÃ§Ã£o com 4 serviÃ§os
  - Remover testes de lÃ³gica movida para serviÃ§os

- â™»ï¸ Update test_conceptModule.test.js
  - Testar orchestration do mÃ³dulo refatorado
  - Testar integraÃ§Ã£o com 4 serviÃ§os
  - Remover duplicaÃ§Ã£o

- âœ… Create test_placesModule.test.js (novo)
  - Testar orchestration
  - Testar integraÃ§Ã£o com PlacesSearchService
  - Testar integraÃ§Ã£o com PlacesUIManager

#### Day 4-5: Workflow Integration
- âœ… audioToMongoDB.test.js
  - Audio recording â†’ conversion â†’ transcription â†’ concepts â†’ save
- âœ… conceptExtraction.test.js
  - Full pipeline with validation
- âœ… placeImport.test.js
  - Google Places â†’ Entity creation
- âœ… conflictResolution.test.js
  - Conflict detection â†’ merge â†’ resolution
- âœ… offlineSync.test.js
  - Offline storage â†’ online sync â†’ conflict handling

**Deliverable:** 10 falhas corrigidas, 50 integration tests atualizados/criados

---

### **Fase 3: Backend Fixes (Week 3) - ALTA** ðŸŸ¡

**Meta:** Corrigir todos os testes backend falhando

#### Day 1-2: Fix AI Fixtures
- ðŸ”§ Fix test_ai_orchestrate.py (14 tests failing)
  - Corrigir fixtures de OpenAI
  - Mock responses adequados
  - Testar error handling

- ðŸ”§ Fix test_integration_transcription.py (5 tests failing)
  - Corrigir audio fixtures
  - Mock de transcriÃ§Ã£o
  - Testar full pipeline

#### Day 3: Backend Unit Tests
- âœ… test_ai_service.py (novo)
- âœ… test_transcription_service.py (novo)
- âœ… test_conflict_resolver.py (novo)
- âœ… test_validators.py (novo)

#### Day 4-5: Backend Integration
- â™»ï¸ Reorganizar testes existentes na nova estrutura
- âœ… test_complete_flow.py (E2E backend)
- ðŸ“Š Coverage report

**Deliverable:** 0 failing tests, +30 unit tests backend

---

### **Fase 4: E2E & Performance (Week 4) - MÃ‰DIA** ðŸŸ¢

**Meta:** Testes E2E reais com Playwright + Performance benchmarks

#### Day 1-2: Setup Playwright
- ðŸ“¦ Install `@playwright/test`
- âš™ï¸ Configure playwright.config.js
- ðŸŽ­ Setup browser contexts
- ðŸ” Mock OAuth for E2E

#### Day 3: Critical E2E Flows
- âœ… completeRestaurantFlow.spec.js
  - Login â†’ Record â†’ Transcribe â†’ Concepts â†’ Save â†’ Sync
- âœ… audioRecordingFlow.spec.js
  - Record â†’ Convert â†’ Upload
- âœ… syncFlow.spec.js
  - Offline edits â†’ Online sync â†’ Conflict resolution

#### Day 4: Edge Cases
- âœ… networkFailure.spec.js
  - Test offline scenarios
- âœ… browserCompatibility.spec.js
  - Chrome, Firefox, Safari
- âœ… dataCorruption.spec.js
  - Recovery scenarios

#### Day 5: Performance Tests
- âœ… audioProcessing.bench.js
  - Conversion performance
- âœ… imageQueue.bench.js
  - Queue throughput
- âœ… syncPerformance.bench.js
  - Sync speed benchmarks

**Deliverable:** 15 E2E tests, 10 performance benchmarks

---

## ðŸ› ï¸ Tools & Configuration

### Frontend Stack

```json
// package.json additions
{
  "devDependencies": {
    "vitest": "^1.6.1",            // âœ… jÃ¡ instalado
    "jsdom": "^24.0.0",            // âœ… jÃ¡ instalado
    "@vitest/ui": "^1.6.1",        // âœ… jÃ¡ instalado
    "@playwright/test": "^1.45.0", // âŒ INSTALAR
    "@vitest/coverage-v8": "^1.6.1" // âœ… jÃ¡ instalado
  }
}
```

**Playwright Config (novo):**
```javascript
// playwright.config.js
import { defineConfig } from '@playwright/test';

export default defineConfig({
  testDir: './tests/e2e',
  timeout: 60000,
  retries: 2,
  workers: 4,
  use: {
    baseURL: 'http://localhost:8000',
    trace: 'on-first-retry',
    screenshot: 'only-on-failure'
  },
  projects: [
    { name: 'chromium', use: { browserName: 'chromium' } },
    { name: 'firefox', use: { browserName: 'firefox' } },
    { name: 'webkit', use: { browserName: 'webkit' } }
  ]
});
```

**Vitest Config Updates:**
```javascript
// vitest.config.js updates
export default defineConfig({
  test: {
    // ... existing config
    
    // NOVO: Suporte a benchmarks
    benchmark: {
      include: ['tests/performance/**/*.bench.js']
    },
    
    // NOVO: Coverage exclusions atualizadas
    coverage: {
      exclude: [
        'tests/**',
        'scripts/modules/*.original*.js', // Backup files
        'scripts/legacy/**'
      ],
      // Aumentar thresholds gradualmente
      statements: 75,  // was 70
      branches: 65,    // was 60
      functions: 75,   // was 70
      lines: 75        // was 70
    }
  }
});
```

### Backend Stack

```python
# requirements-dev.txt (novo)
pytest==8.3.4
pytest-asyncio==0.24.0
pytest-cov==5.0.0              # ADICIONAR - coverage
pytest-benchmark==4.0.0        # ADICIONAR - performance
pytest-xdist==3.6.1            # ADICIONAR - parallel execution
httpx==0.27.0                  # jÃ¡ existe
faker==25.0.0                  # ADICIONAR - fake data
```

**Pytest Config Updates:**
```ini
# pytest.ini updates
[pytest]
markers =
    integration: Integration tests
    external_api: External API tests
    mongo: MongoDB tests
    openai: OpenAI tests
    slow: Slow tests
    benchmark: Performance benchmarks  # NOVO
    
# NOVO: Coverage configuration
addopts = 
    -ra
    --strict-markers
    --disable-warnings
    --tb=short
    --timeout=60
    --cov=app                          # NOVO
    --cov-report=html                  # NOVO
    --cov-report=term-missing          # NOVO
    -n auto                            # NOVO - parallel execution

# NOVO: Coverage thresholds
[coverage:run]
omit = 
    */tests/*
    */conftest.py
    */main.py

[coverage:report]
precision = 2
skip_empty = True
fail_under = 70  # Minimum 70% coverage
```

---

## ðŸ“ Test Writing Standards

### Frontend Test Template

```javascript
/**
 * Test: ServiceName.test.js
 * Purpose: Unit tests for ServiceName
 * Coverage: [list key scenarios]
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { ServiceName } from '../../scripts/services/ServiceName.js';

describe('ServiceName', () => {
  let service;
  
  beforeEach(() => {
    // Setup
    service = new ServiceName();
  });
  
  afterEach(() => {
    // Cleanup
    vi.restoreAllMocks();
  });
  
  describe('Constructor', () => {
    it('should initialize with default values', () => {
      expect(service).toBeDefined();
      expect(service.someProperty).toBe(expectedValue);
    });
    
    it('should throw if dependencies missing', () => {
      window.someUtils = undefined;
      expect(() => new ServiceName()).toThrow('someUtils not loaded');
    });
  });
  
  describe('Method Name', () => {
    it('should [expected behavior]', async () => {
      // Arrange
      const input = 'test data';
      
      // Act
      const result = await service.methodName(input);
      
      // Assert
      expect(result).toBeDefined();
      expect(result.property).toBe(expected);
    });
    
    it('should throw on invalid input', async () => {
      await expect(service.methodName(null))
        .rejects.toThrow('Input is required');
    });
  });
  
  describe('Edge Cases', () => {
    it('should handle empty input', () => {
      // ...
    });
    
    it('should handle large datasets', () => {
      // ...
    });
  });
});
```

### Backend Test Template

```python
"""
Test: test_service_name.py
Purpose: Unit tests for ServiceName
Coverage: [list key scenarios]
"""
import pytest
from app.services.service_name import ServiceName


class TestServiceName:
    """Tests for ServiceName"""
    
    @pytest.fixture
    def service(self):
        """Create service instance"""
        return ServiceName()
    
    def test_initialization(self, service):
        """Should initialize with default values"""
        assert service is not None
        assert service.some_property == expected_value
    
    @pytest.mark.asyncio
    async def test_async_method(self, service):
        """Should [expected behavior]"""
        # Arrange
        input_data = "test"
        
        # Act
        result = await service.async_method(input_data)
        
        # Assert
        assert result is not None
        assert result.property == expected
    
    def test_error_handling(self, service):
        """Should throw on invalid input"""
        with pytest.raises(ValueError, match="Input is required"):
            service.method_name(None)
    
    @pytest.mark.benchmark
    def test_performance(self, benchmark, service):
        """Should process within acceptable time"""
        result = benchmark(lambda: service.method_name("test"))
        assert result is not None
```

---

## ðŸ“Š Success Metrics

### Phase 1 Success Criteria
- âœ… 325+ unit tests created
- âœ… 100% coverage of 10 refactored services
- âœ… 100% coverage of 4 utilities
- âœ… 0 failing unit tests
- âœ… All tests run in <30s

### Phase 2 Success Criteria
- âœ… 0 failing tests (fix 10 current failures)
- âœ… 50+ integration tests updated/created
- âœ… Module tests updated for new architecture
- âœ… 5 workflow integration tests

### Phase 3 Success Criteria
- âœ… 0 failing backend tests
- âœ… 30+ new backend unit tests
- âœ… Backend coverage > 70%
- âœ… All AI tests passing

### Phase 4 Success Criteria
- âœ… 15 E2E tests covering critical flows
- âœ… 10 performance benchmarks
- âœ… E2E tests run in <5min
- âœ… Cross-browser compatibility verified

### Overall Success Criteria
- ðŸ“Š **Total Tests:** 500+ (was 339)
- ðŸ“Š **Pass Rate:** 100% (was 97.9%)
- ðŸ“Š **Frontend Coverage:** 80%+ (was 70%)
- ðŸ“Š **Backend Coverage:** 75%+ (unknown)
- ðŸ“Š **Test Execution:** <2min unit, <5min all
- ðŸ“Š **CI/CD:** All tests automated in pipeline

---

## ðŸ”„ CI/CD Integration

### GitHub Actions Workflow (novo)

```yaml
# .github/workflows/tests.yml
name: Tests

on: [push, pull_request]

jobs:
  frontend-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run unit tests
        run: npm test
      
      - name: Run E2E tests
        run: npm run test:e2e
      
      - name: Generate coverage
        run: npm run test:coverage
      
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage/lcov.info
  
  backend-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        working-directory: ./concierge-api-v3
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Run tests
        working-directory: ./concierge-api-v3
        run: pytest --cov=app --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          files: ./concierge-api-v3/coverage.xml
```

---

## ðŸ“š Documentation Updates Needed

1. **tests/README.md** - Reescrever completamente com nova estrutura
2. **docs/TESTING.md** - Atualizar estratÃ©gia e cobertura
3. **CONTRIBUTING.md** - Adicionar guidelines de teste
4. **package.json scripts** - Adicionar novos comandos
5. **concierge-api-v3/README.md** - Adicionar instruÃ§Ãµes de teste

---

## ðŸ’° EsforÃ§o Estimado

| Fase | Tempo | Custo (dev hours) | Prioridade |
|------|-------|-------------------|------------|
| Fase 1 | 1 semana | 40h | ðŸ”´ CRÃTICA |
| Fase 2 | 1 semana | 25h | ðŸŸ¡ ALTA |
| Fase 3 | 1 semana | 20h | ðŸŸ¡ ALTA |
| Fase 4 | 1 semana | 20h | ðŸŸ¢ MÃ‰DIA |
| **TOTAL** | **4 semanas** | **105h** | - |

---

## ðŸŽ¯ PrÃ³ximos Passos IMEDIATOS

### Esta SessÃ£o (agora)
1. âœ… Revisar e aprovar este plano
2. ðŸ”„ Criar branch `testing-overhaul`
3. ðŸš€ ComeÃ§ar Fase 1 - Day 1 (AudioRecordingService.test.js)

### PrÃ³xima SessÃ£o
1. Continuar Fase 1 - Days 2-5
2. Completar unit tests de todos os serviÃ§os
3. Gerar coverage report

---

## â“ QuestÃµes para DiscussÃ£o

1. **PriorizaÃ§Ã£o:** Concordas com a ordem? Ou prefere comeÃ§ar pelos testes falhando?
2. **Playwright:** Vale a pena E2E real ou focar sÃ³ em unit/integration?
3. **Coverage Targets:** 80% frontend / 75% backend Ã© realista?
4. **Backend Environment:** Configurar pytest no teu ambiente agora ou depois?
5. **CI/CD:** Implementar GitHub Actions na Fase 1 ou deixar para o final?

---

**Status:** â³ AGUARDANDO APROVAÃ‡ÃƒO

Vamos comeÃ§ar? ðŸš€
